# 上下文管理架构设计

> **核心定位**：统一管理 Agent 的所有上下文来源，包括对话历史、记忆系统、知识检索（RAG）、工具调用结果等。
>
> 更新日期：2026-01-17

---

## 一、架构总览

### 1.1 上下文来源全景图

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                        上下文管理（Context Management）                       │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   ┌─────────────────┐   ┌─────────────────┐   ┌─────────────────┐          │
│   │   对话历史       │   │   记忆系统       │   │   知识检索       │          │
│   │  (短期上下文)    │   │  (中期上下文)    │   │  (长期知识库)    │          │
│   ├─────────────────┤   ├─────────────────┤   ├─────────────────┤          │
│   │ Checkpointer    │   │ SimpleMem       │   │ RAG             │          │
│   │ (LangGraph)     │   │ LongTermStore   │   │ VectorStore     │          │
│   │                 │   │ MemoryExtractor │   │ 知识库检索       │          │
│   └────────┬────────┘   └────────┬────────┘   └────────┬────────┘          │
│            │                     │                     │                    │
│            └─────────────────────┼─────────────────────┘                    │
│                                  │                                          │
│                                  ▼                                          │
│            ┌─────────────────────────────────────────────┐                 │
│            │         上下文组装器 (Context Assembler)      │                 │
│            │  • 关键消息检测 (KeyMessageDetector)         │                 │
│            │  • 计划追踪 (PlanTracker)                    │                 │
│            │  • 智能压缩 (SmartContextCompressor)         │                 │
│            │  • 提示词缓存 (PromptCacheManager)           │                 │
│            └─────────────────────┬───────────────────────┘                 │
│                                  │                                          │
│                                  ▼                                          │
│                          LLM 调用 (Prompt)                                  │
│                                                                             │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │                     工具执行结果 (Tool Results)                       │  │
│   │  • 文件读写结果                                                       │  │
│   │  • 代码搜索结果                                                       │  │
│   │  • Shell 执行结果                                                     │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 1.2 上下文来源对比

| 来源 | 存储位置 | 生命周期 | 检索方式 | 与 RAG 关系 |
|------|---------|---------|---------|------------|
| **对话历史** | Checkpointer (Redis/PG) | 会话内 | 全量/滑动窗口 | 不同 |
| **会话记忆** | SimpleMem + VectorStore | 会话内 | 向量 + BM25 | **可整合** |
| **长期记忆** | LongTermStore | 跨会话 | 向量检索 | **可整合** |
| **知识库** | VectorStore | 永久 | 向量检索 | **核心** |
| **工具结果** | 内存 (state) | 单次调用 | 无 | 不同 |

### 1.3 核心设计原则

| 原则 | 说明 |
|------|------|
| **检索宽松** | 检索阶段不跳过任何消息，宁可多召回 |
| **存储严格** | 存储阶段严格过滤，只保留有价值的信息 |
| **分层管理** | 短期/中期/长期分层，各层独立优化 |
| **统一入口** | 避免重复提取，SimpleMem 优先 |
| **可观测性** | 记忆的创建/使用/删除可追踪 |

---

## 二、记忆系统设计

### 2.1 分层架构

```
┌─────────────────────────────────────────────────────────────────┐
│                       分层记忆架构                               │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  ┌─────────────────────────────────────────────────────────┐   │
│  │  工作记忆 (Working Memory)                               │   │
│  │  • 当前对话的消息列表                                    │   │
│  │  • 由 LangGraph Checkpointer 管理                       │   │
│  │  • TTL: 会话结束                                         │   │
│  │  • 检索: 全量（受上下文窗口限制时压缩）                   │   │
│  └─────────────────────────────────────────────────────────┘   │
│                              │                                   │
│                              ▼                                   │
│  ┌─────────────────────────────────────────────────────────┐   │
│  │  短期记忆 (Short-term Memory) - SimpleMem               │   │
│  │  • 会话内长程记忆（解决上下文窗口限制）                   │   │
│  │  • 按 session_id 隔离                                    │   │
│  │  • TTL: 会话结束或配置的过期时间                         │   │
│  │  • 检索: 向量 + BM25 混合                                │   │
│  │  • 存储过滤: novelty_threshold + skip_trivial           │   │
│  └─────────────────────────────────────────────────────────┘   │
│                              │                                   │
│                              ▼                                   │
│  ┌─────────────────────────────────────────────────────────┐   │
│  │  长期记忆 (Long-term Memory) - 未来扩展                  │   │
│  │  • 跨会话的用户偏好、重要事实                            │   │
│  │  • 按 user_id 索引                                       │   │
│  │  • TTL: 永久（或按策略清理）                             │   │
│  │  • 高重要性记忆自动从短期提升                            │   │
│  └─────────────────────────────────────────────────────────┘   │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### 2.2 SimpleMem 核心策略

基于 [SimpleMem 论文](https://arxiv.org/abs/2601.02553)，实现 30x Token 压缩：

```
┌─────────────────────────────────────────────────────────────────┐
│                    SimpleMem 三阶段 Pipeline                     │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│  Stage 1: 语义结构压缩 (Semantic Structured Compression)        │
│  ┌─────────────────────────────────────────────────────────┐   │
│  │  • 滑动窗口处理 (window_size=10, stride=5)              │   │
│  │  • 信息密度过滤 (novelty_threshold=0.35)                │   │
│  │  • 跳过简单问答 (skip_trivial=true)                     │   │
│  └─────────────────────────────────────────────────────────┘   │
│                              ↓                                  │
│  Stage 2: 递归记忆整合 (Recursive Memory Consolidation)         │
│  ┌─────────────────────────────────────────────────────────┐   │
│  │  • 每 50 条记忆触发合并                                  │   │
│  │  • 相似记忆去重                                          │   │
│  └─────────────────────────────────────────────────────────┘   │
│                              ↓                                  │
│  Stage 3: 自适应查询检索 (Adaptive Query-Aware Retrieval)       │
│  ┌─────────────────────────────────────────────────────────┐   │
│  │  • 简单查询: k_min=3                                     │   │
│  │  • 复杂查询: k_max=15                                    │   │
│  │  • 混合检索: 向量 + BM25 + RRF 融合                      │   │
│  └─────────────────────────────────────────────────────────┘   │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
```

### 2.3 统一记忆提取设计

**问题**：原有 `extract_memory` 节点和 `SimpleMem` 后台任务可能重复提取。

**解决方案**：统一使用 SimpleMem，禁用 extract_memory 节点。

```python
# backend/core/engine/langgraph_agent.py
async def _extract_memory(self, state: AgentState):
    # 如果启用了 SimpleMem，跳过此节点
    if settings.simplemem_enabled:
        logger.debug("Skipping extract_memory: SimpleMem is enabled")
        return {}
    # ... 否则使用 MemoryExtractor（作为 fallback）
```

| 对比项 | MemoryExtractor | SimpleMem |
|--------|----------------|-----------|
| 过滤机制 | 无 | ✅ novelty + skip_trivial |
| 检索方式 | 仅向量 | ✅ BM25 + 向量 + RRF |
| 执行方式 | 同步（在图内） | ✅ 异步（后台任务） |
| 对响应影响 | 增加延迟 | ✅ 零延迟 |

---

## 三、混合检索架构

### 3.1 检索策略

```
                      ┌──────────────────┐
                      │   用户查询        │
                      └────────┬─────────┘
                               │
           ┌───────────────────┼───────────────────┐
           │                   │                   │
           ▼                   ▼                   ▼
    ┌──────────────┐   ┌──────────────┐   ┌──────────────┐
    │   BM25       │   │  向量相似度   │   │  元数据过滤   │
    │  词法匹配     │   │  语义匹配     │   │  符号匹配     │
    └──────────────┘   └──────────────┘   └──────────────┘
           │                   │                   │
           └───────────────────┼───────────────────┘
                               │
                               ▼
                      ┌──────────────────┐
                      │  RRF 融合排序     │
                      │  (k=60)          │
                      └──────────────────┘
```

### 3.2 与 RAG 的整合

| 维度 | 记忆系统 | RAG |
|------|---------|-----|
| 数据来源 | 对话生成 | 外部文档 |
| 更新频率 | 实时 | 离线/定期 |
| 生命周期 | 有 TTL | 永久 |
| 检索策略 | **可共用** | **可共用** |
| 向量数据库 | **共用** | **共用** |

**整合点**：
- 共用 VectorStore 基础设施
- 共用 embedding 生成服务
- 可共用混合检索策略（BM25 + 向量 + 元数据）

---

## 四、智能上下文压缩

### 4.1 压缩策略（基于业界最佳实践）

```
┌─────────────────────────────────────────────────────────────────┐
│                      混合记忆架构                                │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│  ┌────────────────────────────────────────────────────────┐     │
│  │  Pinned Memory (固定记忆) - 永不压缩                   │     │
│  │  • 系统提示词                                           │     │
│  │  • 任务定义/目标                                        │     │
│  │  • 用户偏好/约束                                        │     │
│  └────────────────────────────────────────────────────────┘     │
│                          │                                       │
│                          ▼                                       │
│  ┌────────────────────────────────────────────────────────┐     │
│  │  Summary Memory (摘要记忆) - 压缩后保留                 │     │
│  │  • 早期对话摘要                                         │     │
│  │  • 关键决策点                                           │     │
│  │  • 工具执行结果摘要                                     │     │
│  └────────────────────────────────────────────────────────┘     │
│                          │                                       │
│                          ▼                                       │
│  ┌────────────────────────────────────────────────────────┐     │
│  │  Recent Buffer (近期缓冲) - 完整保留                    │     │
│  │  • 最近 M 条完整对话                                    │     │
│  │  • 保持对话连贯性                                       │     │
│  └────────────────────────────────────────────────────────┘     │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
```

### 4.2 核心组件

| 组件 | 功能 | 实现状态 |
|------|------|---------|
| `KeyMessageDetector` | 识别关键消息（任务定义、决策点） | ✅ 已实现 |
| `PlanTracker` | 跟踪任务计划结构 | ✅ 已实现 |
| `SmartContextCompressor` | 智能压缩 | ✅ 已实现 |
| `PromptCacheManager` | 提示词缓存 | ✅ 已实现 |
| `SmartContextManager` | 统一管理器 | ⚠️ 待集成 |

---

## 五、配置参考

### 5.1 SimpleMem 配置

```toml
# config/app.toml

[simplemem]
enabled = true
extraction_model = "dashscope/qwen-turbo"  # 小模型，成本低

[simplemem.window]
size = 10      # 滑动窗口大小
stride = 5     # 步长

[simplemem.filter]
novelty_threshold = 0.35   # 新颖度阈值 (0-1)
skip_trivial = true        # 跳过简单问答
min_content_length = 20

[simplemem.retrieval]
k_min = 3      # 简单查询
k_max = 15     # 复杂查询
complexity_threshold = 0.5

[simplemem.consolidation]
interval = 50  # 合并触发间隔
```

### 5.2 Token 优化配置

```toml
[token_optimization]
prompt_cache_enabled = true

[token_optimization.summarization]
enabled = true
threshold = 8000         # Token 阈值
preserve_recent = 4      # 保留最近 N 条

[token_optimization.tiered_memory]
enabled = true
short_term_ttl_hours = 24
long_term_importance_threshold = 6.0
```

### 5.3 推荐提取模型

| 场景 | 推荐模型 | 成本 |
|------|---------|------|
| 开发测试 | zai/glm-4-flash | 基本免费 |
| 生产（成本优先） | dashscope/qwen-turbo | ¥0.002/千tokens |
| 生产（质量优先） | gpt-4o-mini | $0.15/百万tokens |

---

## 六、调用流程

### 6.1 完整流程图

```
用户消息
    │
    ▼
┌─────────────────────────────────────────────────────────────────┐
│  ChatService.chat()                                              │
│  • 创建/获取会话                                                  │
│  • 保存用户消息                                                   │
└───────────────────────────────┬─────────────────────────────────┘
                                │
                                ▼
┌─────────────────────────────────────────────────────────────────┐
│  LangGraphAgentEngine.run() (状态图)                             │
│                                                                  │
│  ┌──────────────────────────────────────────────────────────┐   │
│  │  1. recall_memory                                         │   │
│  │     • 向量 + BM25 混合检索                                │   │
│  │     • 不跳过任何消息                                      │   │
│  └──────────────────────────────────────────────────────────┘   │
│                    │                                             │
│                    ▼                                             │
│  ┌──────────────────────────────────────────────────────────┐   │
│  │  2. call_llm                                              │   │
│  │     • 构建上下文 (系统提示 + 记忆 + 历史)                 │   │
│  │     • 调用 LLM                                            │   │
│  │     • 解析响应                                            │   │
│  └──────────────────────────────────────────────────────────┘   │
│                    │                                             │
│        ┌──────────┴──────────┐                                  │
│        ▼                     ▼                                   │
│  ┌──────────────┐  ┌──────────────────────────────────────┐     │
│  │ execute_tools│  │ 3. extract_memory                    │     │
│  │ (循环)       │  │    • simplemem_enabled? → 跳过       │     │
│  └──────────────┘  │    • 否则使用 MemoryExtractor        │     │
│                    └──────────────────────────────────────┘     │
└───────────────────────────────┬─────────────────────────────────┘
                                │
                                ▼
┌─────────────────────────────────────────────────────────────────┐
│  后台任务 (异步，不阻塞响应)                                      │
│                                                                  │
│  SimpleMem.process_and_store()                                   │
│  • novelty_threshold 过滤                                        │
│  • skip_trivial 过滤                                             │
│  • LLM 提取原子记忆                                              │
│  • 向量 + BM25 索引                                              │
└─────────────────────────────────────────────────────────────────┘
```

---

## 七、业界最新趋势（2025-2026）

### 7.1 核心趋势

| 趋势 | 说明 | 本项目实现 |
|------|------|-----------|
| **条件触发** | 不是每次都全量更新/检索 | ✅ novelty 过滤 |
| **混合检索** | BM25 + 向量 + 元数据 | ✅ SimpleMem |
| **分层记忆** | 工作/短期/长期 | ✅ 已实现 |
| **Agent 自主管理** | 记忆作为工具 | ❌ 待实现 |
| **类型化记忆** | episodic/semantic/procedural | ❌ 待实现 |
| **可更新记忆** | 冲突检测、版本管理 | ❌ 待实现 |

### 7.2 参考系统

| 系统 | 特点 |
|------|------|
| **MemGPT/Letta** | Agent 自主决定何时存储/检索 |
| **ENGRAM** | 类型化记忆（episodic/semantic/procedural） |
| **Mem0** | 分层记忆 + 显著降低 Token 成本 |
| **SimpleMem** | 30x 压缩 + 混合检索 |

---

## 八、多技术整合规划

> 详细整合方案见：[最新论文对照分析](./LATEST_PAPERS_ALIGNMENT.md)

### 8.1 整合架构概览

```
Layer 1: 主题分段 (SeCom)         ← Phase 3
Layer 2: 计划感知 (PAACE)         ← ✅ 已有
Layer 3: 重要性 + 干扰过滤        ← Phase 4 (Sculptor)
Layer 4: 分层存储 (Cognitive WS)  ← Phase 2
Layer 5: 混合检索 (SimpleMem)     ← ✅ 已有
```

### 8.2 实施路线图

| Phase | 时间 | 目标 | 技术 |
|-------|------|------|------|
| **P1** | 1-2 周 | 统一压缩入口 + 监控 | SimpleMem + PAACE |
| **P2** | 2-3 周 | 三层缓冲架构 | Cognitive Workspace |
| **P3** | 2 周 | 主题分段检索 | SeCom |
| **P4** | 3-4 周 | Hide/Restore + 记忆工具化 | Sculptor + AgeMem |
| **P5** | 持续 | Benchmark + A/B 测试 | - |

### 8.3 各技术选择理由

| 功能 | 选用 | 理由 | 替代方案 |
|------|------|------|---------|
| 压缩核心 | SimpleMem | 30x 压缩，最全面 | PAACE 压缩能力弱 |
| 计划感知 | PAACE | 独特能力，与 SimpleMem 互补 | - |
| 分层架构 | Cognitive WS | 认知缓冲概念先进 | 融合 SimpleMem |
| 干扰过滤 | Sculptor | Hide/Restore 独特 | - |
| 工具化 | AgeMem | Agent 自主管理 | - |

---

## 九、相关文档

- [上下文管理最佳实践](./CONTEXT_MANAGEMENT_BEST_PRACTICES.md) - 业界研究综述
- [上下文管理实施方案](./CONTEXT_MANAGEMENT_IMPLEMENTATION.md) - 本项目实施指南
- [Token 优化策略](./TOKEN_OPTIMIZATION_STRATEGY.md) - 成本优化
- [记忆和会话功能整合文档](../../记忆和会话功能整合文档.md) - 历史设计文档

---

## 十、参考资料

### 论文

- [SimpleMem](https://arxiv.org/abs/2601.02553) - 30x Token 压缩
- [ENGRAM](https://arxiv.org/abs/2511.12960) - 类型化记忆
- [Mem0](https://arxiv.org/abs/2504.19413) - 分层记忆架构
- [PAACE](https://arxiv.org/abs/2412.00000) - 计划感知上下文工程

### 开源项目

- [Letta/MemGPT](https://github.com/letta-ai/letta) - Agent 自主记忆管理
- [LangGraph](https://github.com/langchain-ai/langgraph) - 状态图 + Checkpointer
